bundle:
  name: databricks-project

environments:
  dev:
    workspace:
      host: https://dbc-3046d6f1-8d0b.cloud.databricks.com
      root_path: /Workspace/Users/pranathibts5117@gmail.com/bundles/sql_automation_bundle

  prod:
    workspace:
      host: https://dbc-3046d6f1-8d0b.cloud.databricks.com
      root_path: /Workspace/Users/pranathibts5117@gmail.com/bundles/sql_automation_bundle_prod

resources:
  jobs:
    # Job 1: Creates date_table
    # date_table_job:
    #   name: "Date Table Job"
    #   tasks:
    #     - task_key: create_date_table
    #       sql_task:
    #         file:
    #           path: ./assets/notebooks/query.sql
    #         warehouse_id: "f68b5a932e3471dc"
    #   # schedule:
    #   #   quartz_cron_expression: "0 0 6 ? * *"  # every day at 6 AM UTC (11:30 AM IST)
    #   #   timezone_id: "Asia/Kolkata"
    
    # # Job 2: Creates daily_sales table
    # daily_sales_job:
    #   name: "Daily Sales Job"
    #   tasks:
    #     - task_key: create_daily_sales
    #       sql_task:
    #         file:
    #           path: ./assets/notebooks/transform_data.sql
    #         warehouse_id: "f68b5a932e3471dc"
    
    # Job 3: Python job - Creates table using Python/Spark
    # Note: Requires compute cluster (not SQL warehouse)
    employees_job:
      name: "Employees Table Creation Job"
      tasks:
        - task_key: create_employees_table
          notebook_task:
            notebook_path: ./assets/notebooks/create_table_employees
          warehouse_id: "f68b5a932e3471dc"
